
lvm:
  # This one you should change
  devicePattern: /dev/nvme[0-9]n[0-9]

  # these are primariliy for testing purposes
  vgName: csi-lvm
  driverName: lvm.csi.metal-stack.io
  storageClassStub: csi-lvm

pluginImage:
  repository: metalstack/lvmplugin
  tag: v0.4.1
  pullPolicy: IfNotPresent

provisionerImage:
  repository: metalstack/csi-lvmplugin-provisioner
  tag: v0.4.1
  pullPolicy: IfNotPresent

rbac:
  create: true
  pspEnabled: true

kubernetes:
  kubeletPath: /var/lib/kubelet

storageClasses:
  linear:
    enabled: true
    additionalAnnotations: []
    # this might be used to mark one of the StorageClasses as default:
    # storageclass.kubernetes.io/is-default-class: "true"
  striped:
    enabled: true
    additionalAnnotations: []
  mirror:
    enabled: true
    additionalAnnotations: []

nodeSelector:
  # The plugin daemonset will run on all nodes if it has a toleration,
  # so it is not necessary to set a nodeSelector for it

  # The provisioner has an affinity for nodes with a plugin pod,
  # but since that's a daemonset, we allow more fine-grained node selection

  #provisioner:
    #node-role.kubernetes.io/master: ""
    ## Key name may need to be updated to 'node-role.kubernetes.io/control-plane'
    ## in the future

tolerations:
  #plugin:
  #- key: node-role.kubernetes.io/master
  #  operator: Exists
  #  effect: NoSchedule
  #- key: node-role.kubernetes.io/control-plane
  #  operator: Exists
  #  effect: NoSchedule
  #provisioner:
  #- key: node-role.kubernetes.io/master
  #  operator: Exists
  #  effect: NoSchedule
  #- key: node-role.kubernetes.io/control-plane
  #  operator: Exists
  #  effect: NoSchedule
